{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvWTVnvUgELBhLOPUx2tCn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedalifaragitiai/NLP/blob/main/Session_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O94YQFuvILIt"
      },
      "outputs": [],
      "source": [
        "#!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "l3O8Qxi0VY2f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "fe-eP2VgV_5t"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer"
      ],
      "metadata": {
        "id": "2gJNQRYvWLLG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('twitter_samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWTv7qaTWSWg",
        "outputId": "6290c852-fdbc-4113-861b-df54810935bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import twitter_samples"
      ],
      "metadata": {
        "id": "KXRTFyQrWiZw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')"
      ],
      "metadata": {
        "id": "sKdaQwkQW1FI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "metadata": {
        "id": "hCMRio6uXMB1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_positive_tweets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YEOB6_rX2i8",
        "outputId": "5e2d8205-4f45-4578-d3d0-9ba0db9b77d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_positive_tweets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrsKr5rfX8or",
        "outputId": "25a18bca-a589-4c25-d568-e4b83ea626e4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(all_positive_tweets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfocuQE3X-85",
        "outputId": "9dc84798-eb95-41c3-9bd6-2f6b05570e82"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(all_negative_tweets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcVvwtV8YK2J",
        "outputId": "bd624993-2011-4eec-c31d-2553d541144a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(all_negative_tweets[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utE8cLdWYNcr",
        "outputId": "0c128595-a543-4e95-c65a-7eb412c80da9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag.perceptron import random\n",
        "all_positive_tweets[random.randint(0,5000)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SUgiJMAlYSV1",
        "outputId": "90424a06-2f3b-44bd-cece-91d5fe988b69"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'@yvonneainah I love you! :)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_negative_tweets[random.randint(0,5000)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BZ6OvdS2Zwim",
        "outputId": "040ca064-c930-44cc-e6f7-4491e46184f0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I want to ESCAPE please :('"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PExhNN9oZ8lA",
        "outputId": "a652ab9a-2e2f-4223-fe34-b85b1bf9f083"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "1Gz6w7TaaKL1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "P0NIkcsdaRO5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TweetTokenizer"
      ],
      "metadata": {
        "id": "PgIv7O2KaVDS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = '''My beautiful sunflowers on a sunny Friday morning \n",
        "off :) #sunflowers #favourites #happy #Friday off... \n",
        "https://t.co/3tfYom0N1i'''"
      ],
      "metadata": {
        "id": "J23rqo1JTftR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTbgcgVGaZ4a",
        "outputId": "6ea020e2-8b4a-4e45-c91b-c18529340af0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My beautiful sunflowers on a sunny Friday morning \n",
            "off :) #sunflowers #favourites #happy #Friday off... \n",
            "https://t.co/3tfYom0N1i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove old style retweet text \"RT\""
      ],
      "metadata": {
        "id": "vvgQFeoJUSR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "wFi8a4Q-UbVq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet2 = re.sub(r'^RT[\\s]+', '', tweet)"
      ],
      "metadata": {
        "id": "bZi1_qoiatFg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove hyperlink"
      ],
      "metadata": {
        "id": "7cItxG_NUtkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweet2 = re.sub(r'https?:\\/\\/.*[\\r]*', '', tweet2)"
      ],
      "metadata": {
        "id": "9oayEdOiUpL_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove hashtages, only removing the hash # sign from the word"
      ],
      "metadata": {
        "id": "XUr36OIYU9e0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweet2 = re.sub(r'#', '', tweet2)"
      ],
      "metadata": {
        "id": "EML9a7FGU83s"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6XtQcQqkVN5v",
        "outputId": "2d195917-ef3d-4551-97d3-03297d40782c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'My beautiful sunflowers on a sunny Friday morning \\noff :) sunflowers favourites happy Friday off... \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet2 = re.sub(r'\\n', '', tweet2)"
      ],
      "metadata": {
        "id": "xvllPHThVRAV"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FQNObvx1Vz9_",
        "outputId": "a70112bd-6a9b-4911-af15-2a59e6671b69"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'My beautiful sunflowers on a sunny Friday morning off :) sunflowers favourites happy Friday off... '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**split the tweets into array of words.**"
      ],
      "metadata": {
        "id": "9RDEPvE4V9cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import tokenize\n",
        "#instantiate tokenizer class\n",
        "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)"
      ],
      "metadata": {
        "id": "Lo7EiBMnV0zj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize tweets\n",
        "tweet_tokens = tokenizer.tokenize(tweet2)"
      ],
      "metadata": {
        "id": "uL4iMChhWYFr"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tokenized string: ', '\\n', tweet_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8xWGKxeWpwg",
        "outputId": "36aced21-36d2-47fd-f8f9-729895c6e6b7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized string:  \n",
            " ['my', 'beautiful', 'sunflowers', 'on', 'a', 'sunny', 'friday', 'morning', 'off', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'off', '...']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To remove stop words and punctuation**"
      ],
      "metadata": {
        "id": "kAVsbxPNXCko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the English stop words list from NLTK\n",
        "stopwords_english = stopwords.words('english')"
      ],
      "metadata": {
        "id": "hEwDwmS_W173"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_english"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljAdyOToXSVI",
        "outputId": "944e5a15-1ff5-4c41-b4a3-bcf23e7bfc01"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string"
      ],
      "metadata": {
        "id": "Z9jCgA1lX3xm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fBZBT6-aXUZD",
        "outputId": "a47a3ddc-ded9-4256-c8d2-2f454ec72f9a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Now, we clean our tweet.**"
      ],
      "metadata": {
        "id": "88a04z-kX_cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_clean = []"
      ],
      "metadata": {
        "id": "NJw3Zo7VXkNc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in tweet_tokens: #Go through every word in your tokens list\n",
        "  if (word not in stopwords_english and #remove stopwords\n",
        "      word not in string.punctuation): #remove punctuation\n",
        "    tweets_clean.append(word)"
      ],
      "metadata": {
        "id": "0vY9O85_YFW2"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Removed stop words and punctuations: ', '\\n', tweets_clean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF8P3EhoYoXV",
        "outputId": "30fb7908-5f26-49f1-8842-dd41fef071b0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed stop words and punctuations:  \n",
            " ['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', '...']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming**\n"
      ],
      "metadata": {
        "id": "H4hrFpQrY_sJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate stemming class\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "#Create an empty list to store the stems\n",
        "tweets_stem = []\n",
        "\n",
        "for word in tweets_clean:\n",
        "  stem_word = stemmer.stem(word) # stemming word\n",
        "  tweets_stem.append(stem_word) # append to the list\n"
      ],
      "metadata": {
        "id": "l3ljKT1MY0f6"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('stemmed words: ', '\\n', tweets_stem)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uIZzC-oZw8e",
        "outputId": "1560b2ae-5ec3-40cc-dc81-60abe6eccd1a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stemmed words:  \n",
            " ['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', '...']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Process Tweets**"
      ],
      "metadata": {
        "id": "SLGrF8mcaR9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tweet(tweet):\n",
        "  stemmer = PorterStemmer()\n",
        "  stopwords_english = stopwords.words('english')\n",
        "  #remove stock market trickers like $GE\n",
        "  tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "  #remove old style retweet text \"RT\"\n",
        "  tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "  #remove hyperlinkes\n",
        "  tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "  #to remove \\n \n",
        "  tweet = re.sub(r'\\n', '', tweet)\n",
        "  tweet = re.sub(r'#', '', tweet)\n",
        "  #tokenize tweets\n",
        "  tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "  tweet_tokens = tokenizer.tokenize(tweet)\n",
        "  return tweet_tokens"
      ],
      "metadata": {
        "id": "vC-e3JYMZ7tC"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Extraction** build the words frequency \n",
        "table."
      ],
      "metadata": {
        "id": "QPIlc9iyeUkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def build_freqs(tweets,ys):\n",
        "  # convert np array to list scince zip needs an iterable.\n",
        "  # the squeez is necessary or the list ends up with one element.\n",
        "  # also note that this is just n NOP if ys is already a list.\n",
        "  yslist = np.squeeze(ys).tolist()\n",
        "\n",
        "  #start with an empty dictionary and populate it by looping over all tweets\n",
        "  # and over all processed words in each tweet.\n",
        "  freqs = {}\n",
        "  for y, tweet in zip(yslist, tweets):\n",
        "    for word in process_tweet(tweet):\n",
        "      pair = (word, y)\n",
        "      if pair in freqs:\n",
        "        freqs[pair] += 1\n",
        "      else:\n",
        "        freqs[pair] = 1\n",
        "  return freqs"
      ],
      "metadata": {
        "id": "fcW0TLlgcNce"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**After getting the frequencies of all unique words, we extract the \n",
        "features vector for each tweet.**"
      ],
      "metadata": {
        "id": "U2WE7lJ2gnaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(tweet, freqs):\n",
        "  # process tweet tokenizes, stems, and removes stopwords\n",
        "  word_l = process_tweet(tweet)\n",
        "  # 3 elements in the form of a 1 x 3 vector\n",
        "  x = np.zeros((1,3))\n",
        "  # bais term is set to 1\n",
        "  x[0,0] = 1\n",
        "  # loop through each word in the list of words \n",
        "  for word in word_l:\n",
        "    # increment the word count for the positive label 1\n",
        "    x[0,1] += freqs.get((word, 1.0),0)\n",
        "    # increment the word count for the negative label 0\n",
        "    x[0,2] += freqs.get((word, 0.0), 0)\n",
        "  assert(x.shape == (1, 3))\n",
        "  return x"
      ],
      "metadata": {
        "id": "rRyXBuydgiRe"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare the data for our model.\n"
      ],
      "metadata": {
        "id": "ds016X00iEK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split the data into two pices, one for training and one for testing \n",
        "\n",
        "test_pos = all_positive_tweets[4000:]\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "\n",
        "train_x = train_pos + train_neg \n",
        "test_x = test_pos + test_neg\n",
        "\n",
        "train_y = np.append(np.ones((len(train_pos),1)), np.zeros((len(train_neg),1)), axis = 0)\n",
        "\n",
        "test_y = np.append(np.ones((len(test_pos),1)), np.zeros((len(test_neg),1)), axis = 0)"
      ],
      "metadata": {
        "id": "Glj_ahtph_l7"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Frequencies dictionary for the training data.**"
      ],
      "metadata": {
        "id": "0g28JVQZjkhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = build_freqs(train_x, train_y)"
      ],
      "metadata": {
        "id": "ZeS7UBfbjgTc"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('type(freqs) = ' + str(type(freqs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc9VM_Y_jud3",
        "outputId": "ebc67978-5be8-41ee-f5f5-76d3b8c45383"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(freqs) = <class 'dict'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"len(freqs) = \"+ str(len(freqs.keys())) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAVLb2b2l-FW",
        "outputId": "9ca788f8-3f26-4fd3-f401-cde868c83c89"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(freqs) = 13562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NRIDbG1mN9o",
        "outputId": "90d99757-808a-410b-eead-cfb33d33c8b6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('followfriday', 1.0): 23,\n",
              " ('for', 1.0): 606,\n",
              " ('being', 1.0): 49,\n",
              " ('top', 1.0): 29,\n",
              " ('engaged', 1.0): 7,\n",
              " ('members', 1.0): 10,\n",
              " ('in', 1.0): 381,\n",
              " ('my', 1.0): 441,\n",
              " ('community', 1.0): 25,\n",
              " ('this', 1.0): 241,\n",
              " ('week', 1.0): 61,\n",
              " (':)', 1.0): 2847,\n",
              " ('hey', 1.0): 59,\n",
              " ('james', 1.0): 7,\n",
              " ('!', 1.0): 1455,\n",
              " ('how', 1.0): 60,\n",
              " ('odd', 1.0): 1,\n",
              " (':/', 1.0): 5,\n",
              " ('please', 1.0): 77,\n",
              " ('call', 1.0): 21,\n",
              " ('our', 1.0): 111,\n",
              " ('contact', 1.0): 4,\n",
              " ('centre', 1.0): 1,\n",
              " ('on', 1.0): 242,\n",
              " ('02392441234', 1.0): 1,\n",
              " ('and', 1.0): 553,\n",
              " ('we', 1.0): 182,\n",
              " ('will', 1.0): 150,\n",
              " ('be', 1.0): 198,\n",
              " ('able', 1.0): 6,\n",
              " ('to', 1.0): 836,\n",
              " ('assist', 1.0): 1,\n",
              " ('you', 1.0): 1185,\n",
              " ('many', 1.0): 28,\n",
              " ('thanks', 1.0): 310,\n",
              " ('had', 1.0): 35,\n",
              " ('a', 1.0): 725,\n",
              " ('listen', 1.0): 8,\n",
              " ('last', 1.0): 36,\n",
              " ('night', 1.0): 49,\n",
              " ('as', 1.0): 82,\n",
              " ('bleed', 1.0): 2,\n",
              " ('is', 1.0): 353,\n",
              " ('an', 1.0): 98,\n",
              " ('amazing', 1.0): 39,\n",
              " ('track', 1.0): 5,\n",
              " ('.', 1.0): 984,\n",
              " ('when', 1.0): 69,\n",
              " ('are', 1.0): 152,\n",
              " ('scotland', 1.0): 2,\n",
              " ('?', 1.0): 462,\n",
              " ('congrats', 1.0): 15,\n",
              " ('yeaaah', 1.0): 1,\n",
              " ('yipppy', 1.0): 1,\n",
              " ('accnt', 1.0): 2,\n",
              " ('verified', 1.0): 1,\n",
              " ('rqst', 1.0): 1,\n",
              " ('has', 1.0): 38,\n",
              " ('succeed', 1.0): 1,\n",
              " ('got', 1.0): 56,\n",
              " ('blue', 1.0): 8,\n",
              " ('tick', 1.0): 1,\n",
              " ('mark', 1.0): 1,\n",
              " ('fb', 1.0): 4,\n",
              " ('profile', 1.0): 2,\n",
              " ('15', 1.0): 4,\n",
              " ('days', 1.0): 30,\n",
              " ('one', 1.0): 87,\n",
              " ('irresistible', 1.0): 2,\n",
              " ('flipkartfashionfriday', 1.0): 15,\n",
              " (\"don't\", 1.0): 69,\n",
              " ('like', 1.0): 177,\n",
              " ('keep', 1.0): 46,\n",
              " ('lovely', 1.0): 48,\n",
              " ('customers', 1.0): 2,\n",
              " ('waiting', 1.0): 23,\n",
              " ('long', 1.0): 27,\n",
              " ('hope', 1.0): 97,\n",
              " ('enjoy', 1.0): 40,\n",
              " ('happy', 1.0): 148,\n",
              " ('friday', 1.0): 86,\n",
              " ('-', 1.0): 165,\n",
              " ('lwwf', 1.0): 1,\n",
              " ('second', 1.0): 8,\n",
              " ('thought', 1.0): 20,\n",
              " (',', 1.0): 772,\n",
              " ('there', 1.0): 66,\n",
              " ('’', 1.0): 17,\n",
              " ('s', 1.0): 26,\n",
              " ('just', 1.0): 165,\n",
              " ('not', 1.0): 115,\n",
              " ('enough', 1.0): 16,\n",
              " ('time', 1.0): 89,\n",
              " ('dd', 1.0): 1,\n",
              " ('but', 1.0): 142,\n",
              " ('new', 1.0): 110,\n",
              " ('shorts', 1.0): 1,\n",
              " ('entering', 1.0): 1,\n",
              " ('system', 1.0): 2,\n",
              " ('sheep', 1.0): 1,\n",
              " ('must', 1.0): 14,\n",
              " ('buying', 1.0): 1,\n",
              " ('jgh', 1.0): 4,\n",
              " ('have', 1.0): 343,\n",
              " ('go', 1.0): 68,\n",
              " ('bayan', 1.0): 1,\n",
              " (':D', 1.0): 498,\n",
              " ('bye', 1.0): 5,\n",
              " ('act', 1.0): 4,\n",
              " ('of', 1.0): 329,\n",
              " ('mischievousness', 1.0): 1,\n",
              " ('am', 1.0): 63,\n",
              " ('calling', 1.0): 4,\n",
              " ('the', 1.0): 873,\n",
              " ('etl', 1.0): 1,\n",
              " ('layer', 1.0): 1,\n",
              " ('in-house', 1.0): 1,\n",
              " ('warehousing', 1.0): 1,\n",
              " ('app', 1.0): 11,\n",
              " ('katamari.well', 1.0): 1,\n",
              " ('…', 1.0): 31,\n",
              " ('name', 1.0): 10,\n",
              " ('implies', 1.0): 1,\n",
              " (':p', 1.0): 103,\n",
              " ('influencers', 1.0): 10,\n",
              " ('who', 1.0): 42,\n",
              " (\"wouldn't\", 1.0): 6,\n",
              " ('love', 1.0): 225,\n",
              " ('these', 1.0): 18,\n",
              " ('big', 1.0): 27,\n",
              " ('...', 1.0): 228,\n",
              " ('juicy', 1.0): 3,\n",
              " ('selfies', 1.0): 6,\n",
              " ('follow', 1.0): 210,\n",
              " ('&', 1.0): 153,\n",
              " ('perfect', 1.0): 16,\n",
              " ('so', 1.0): 232,\n",
              " ('already', 1.0): 19,\n",
              " ('know', 1.0): 113,\n",
              " (\"what's\", 1.0): 14,\n",
              " ('great', 1.0): 134,\n",
              " ('opportunity', 1.0): 2,\n",
              " ('junior', 1.0): 2,\n",
              " ('triathletes', 1.0): 1,\n",
              " ('aged', 1.0): 1,\n",
              " ('12', 1.0): 5,\n",
              " ('13', 1.0): 5,\n",
              " ('at', 1.0): 144,\n",
              " ('gatorade', 1.0): 1,\n",
              " ('series', 1.0): 4,\n",
              " ('get', 1.0): 135,\n",
              " ('your', 1.0): 263,\n",
              " ('entries', 1.0): 1,\n",
              " ('laying', 1.0): 2,\n",
              " ('out', 1.0): 86,\n",
              " ('greetings', 1.0): 3,\n",
              " ('card', 1.0): 5,\n",
              " ('range', 1.0): 1,\n",
              " ('print', 1.0): 1,\n",
              " ('today', 1.0): 85,\n",
              " ('job', 1.0): 33,\n",
              " (':-)', 1.0): 543,\n",
              " (\"friend's\", 1.0): 3,\n",
              " ('lunch', 1.0): 3,\n",
              " ('yummm', 1.0): 1,\n",
              " ('nostalgia', 1.0): 1,\n",
              " ('tbs', 1.0): 1,\n",
              " ('ku', 1.0): 1,\n",
              " ('it', 1.0): 394,\n",
              " ('id', 1.0): 7,\n",
              " ('conflict', 1.0): 1,\n",
              " ('help', 1.0): 28,\n",
              " (\"here's\", 1.0): 20,\n",
              " ('screenshot', 1.0): 1,\n",
              " ('working', 1.0): 28,\n",
              " ('hi', 1.0): 154,\n",
              " ('liv', 1.0): 2,\n",
              " (')', 1.0): 419,\n",
              " ('hello', 1.0): 49,\n",
              " ('i', 1.0): 876,\n",
              " ('need', 1.0): 47,\n",
              " ('something', 1.0): 24,\n",
              " ('can', 1.0): 166,\n",
              " ('u', 1.0): 136,\n",
              " ('fm', 1.0): 2,\n",
              " ('me', 1.0): 268,\n",
              " ('twitter', 1.0): 25,\n",
              " ('—', 1.0): 22,\n",
              " ('sure', 1.0): 35,\n",
              " ('thing', 1.0): 26,\n",
              " ('dm', 1.0): 31,\n",
              " ('x', 1.0): 50,\n",
              " ('followers', 1.0): 26,\n",
              " (\"i've\", 1.0): 25,\n",
              " ('heard', 1.0): 9,\n",
              " ('four', 1.0): 5,\n",
              " ('seasons', 1.0): 1,\n",
              " ('pretty', 1.0): 17,\n",
              " ('dope', 1.0): 2,\n",
              " ('penthouse', 1.0): 1,\n",
              " ('obvs', 1.0): 1,\n",
              " ('gobigorgohomehave', 1.0): 1,\n",
              " ('fun', 1.0): 45,\n",
              " (\"y'all\", 1.0): 3,\n",
              " ('yeah', 1.0): 30,\n",
              " ('suppose', 1.0): 5,\n",
              " ('she', 1.0): 69,\n",
              " ('was', 1.0): 116,\n",
              " ('lol', 1.0): 47,\n",
              " ('chat', 1.0): 9,\n",
              " ('bit', 1.0): 15,\n",
              " ('off', 1.0): 28,\n",
              " ('youth', 1.0): 14,\n",
              " ('opportunities', 1.0): 14,\n",
              " ('>', 1.0): 48,\n",
              " ('💅🏽', 1.0): 1,\n",
              " ('💋', 1.0): 2,\n",
              " (\"haven't\", 1.0): 12,\n",
              " ('seen', 1.0): 6,\n",
              " ('years', 1.0): 10,\n",
              " ('thank', 1.0): 191,\n",
              " ('rest', 1.0): 9,\n",
              " ('goes', 1.0): 4,\n",
              " ('by', 1.0): 31,\n",
              " ('quickly', 1.0): 3,\n",
              " ('bed', 1.0): 8,\n",
              " ('music', 1.0): 15,\n",
              " ('fix', 1.0): 3,\n",
              " ('now', 1.0): 90,\n",
              " ('dream', 1.0): 13,\n",
              " ('spiritual', 1.0): 1,\n",
              " ('ritual', 1.0): 1,\n",
              " ('festival', 1.0): 7,\n",
              " ('(', 1.0): 66,\n",
              " ('népal', 1.0): 1,\n",
              " ('beginning', 1.0): 3,\n",
              " ('line-up', 1.0): 4,\n",
              " ('left', 1.0): 10,\n",
              " ('y', 1.0): 5,\n",
              " ('see', 1.0): 142,\n",
              " ('more', 1.0): 80,\n",
              " (':', 1.0): 192,\n",
              " ('sarah', 1.0): 4,\n",
              " ('send', 1.0): 7,\n",
              " ('us', 1.0): 91,\n",
              " ('email', 1.0): 19,\n",
              " ('bitsy@bitdefender.com', 1.0): 1,\n",
              " (\"we'll\", 1.0): 12,\n",
              " ('asap', 1.0): 5,\n",
              " ('lols', 1.0): 1,\n",
              " ('kik', 1.0): 16,\n",
              " ('hatessuce', 1.0): 1,\n",
              " ('32429', 1.0): 1,\n",
              " ('kikme', 1.0): 1,\n",
              " ('lgbt', 1.0): 2,\n",
              " ('tinder', 1.0): 1,\n",
              " ('nsfw', 1.0): 1,\n",
              " ('akua', 1.0): 1,\n",
              " ('cumshot', 1.0): 1,\n",
              " ('come', 1.0): 42,\n",
              " ('house', 1.0): 4,\n",
              " ('nsn_supplements', 1.0): 1,\n",
              " ('effective', 1.0): 1,\n",
              " ('press', 1.0): 1,\n",
              " ('release', 1.0): 8,\n",
              " ('distribution', 1.0): 1,\n",
              " ('with', 1.0): 178,\n",
              " ('results', 1.0): 2,\n",
              " ('[', 1.0): 9,\n",
              " ('link', 1.0): 10,\n",
              " ('removed', 1.0): 2,\n",
              " (']', 1.0): 9,\n",
              " ('pressrelease', 1.0): 1,\n",
              " ('newsdistribution', 1.0): 1,\n",
              " ('bam', 1.0): 44,\n",
              " ('bestfriend', 1.0): 49,\n",
              " ('loves', 1.0): 50,\n",
              " ('lot', 1.0): 71,\n",
              " ('warsaw', 1.0): 44,\n",
              " ('<3', 1.0): 118,\n",
              " ('x46', 1.0): 1,\n",
              " ('everyone', 1.0): 45,\n",
              " ('watch', 1.0): 16,\n",
              " ('documentary', 1.0): 1,\n",
              " ('earthlings', 1.0): 1,\n",
              " ('youtube', 1.0): 7,\n",
              " ('supports', 1.0): 6,\n",
              " ('buuut', 1.0): 1,\n",
              " ('oh', 1.0): 44,\n",
              " ('well', 1.0): 63,\n",
              " ('looking', 1.0): 45,\n",
              " ('forward', 1.0): 20,\n",
              " ('visiting', 1.0): 2,\n",
              " ('next', 1.0): 37,\n",
              " ('letsgetmessy', 1.0): 1,\n",
              " ('jo', 1.0): 1,\n",
              " ('if', 1.0): 141,\n",
              " ('makes', 1.0): 12,\n",
              " ('feel', 1.0): 22,\n",
              " ('better', 1.0): 40,\n",
              " ('never', 1.0): 31,\n",
              " ('nor', 1.0): 1,\n",
              " ('anyone', 1.0): 7,\n",
              " ('kpop', 1.0): 1,\n",
              " ('flesh', 1.0): 1,\n",
              " ('good', 1.0): 188,\n",
              " ('girl', 1.0): 22,\n",
              " ('best', 1.0): 48,\n",
              " ('wishes', 1.0): 3,\n",
              " ('reason', 1.0): 8,\n",
              " ('epic', 1.0): 1,\n",
              " ('soundtrack', 1.0): 1,\n",
              " ('shout', 1.0): 9,\n",
              " ('added', 1.0): 8,\n",
              " ('video', 1.0): 25,\n",
              " ('playlist', 1.0): 5,\n",
              " ('would', 1.0): 70,\n",
              " ('dear', 1.0): 15,\n",
              " ('jordan', 1.0): 1,\n",
              " ('okay', 1.0): 31,\n",
              " ('fake', 1.0): 1,\n",
              " ('gameplays', 1.0): 1,\n",
              " (';)', 1.0): 22,\n",
              " ('haha', 1.0): 44,\n",
              " ('im', 1.0): 38,\n",
              " ('kidding', 1.0): 4,\n",
              " ('do', 1.0): 120,\n",
              " ('stuff', 1.0): 11,\n",
              " ('exactly', 1.0): 5,\n",
              " ('product', 1.0): 3,\n",
              " ('line', 1.0): 3,\n",
              " ('etsy', 1.0): 1,\n",
              " ('shop', 1.0): 7,\n",
              " ('check', 1.0): 35,\n",
              " ('vacation', 1.0): 5,\n",
              " ('going', 1.0): 52,\n",
              " ('they', 1.0): 48,\n",
              " ('rechargeable', 1.0): 1,\n",
              " ('normally', 1.0): 2,\n",
              " ('comes', 1.0): 5,\n",
              " ('charger', 1.0): 2,\n",
              " ('buy', 1.0): 8,\n",
              " (\"she's\", 1.0): 7,\n",
              " ('asleep', 1.0): 7,\n",
              " ('no', 1.0): 136,\n",
              " ('talk', 1.0): 19,\n",
              " ('sooo', 1.0): 6,\n",
              " ('someone', 1.0): 29,\n",
              " ('text', 1.0): 11,\n",
              " ('yes', 1.0): 58,\n",
              " ('bet', 1.0): 5,\n",
              " (\"he'll\", 1.0): 2,\n",
              " ('fit', 1.0): 2,\n",
              " ('after', 1.0): 17,\n",
              " ('hearing', 1.0): 1,\n",
              " ('her', 1.0): 35,\n",
              " ('speech', 1.0): 1,\n",
              " ('pity', 1.0): 2,\n",
              " ('green', 1.0): 2,\n",
              " ('gardens', 1.0): 1,\n",
              " ('midnight', 1.0): 1,\n",
              " ('sun', 1.0): 6,\n",
              " ('beautiful', 1.0): 39,\n",
              " ('canals', 1.0): 1,\n",
              " ('dasvidaniya', 1.0): 1,\n",
              " ('till', 1.0): 16,\n",
              " ('visit', 1.0): 21,\n",
              " ('scouting', 1.0): 1,\n",
              " ('sg', 1.0): 1,\n",
              " ('future', 1.0): 9,\n",
              " ('wlan', 1.0): 1,\n",
              " ('pros', 1.0): 1,\n",
              " ('conference', 1.0): 1,\n",
              " ('here', 1.0): 89,\n",
              " ('asia', 1.0): 1,\n",
              " ('change', 1.0): 9,\n",
              " ('lollipop', 1.0): 1,\n",
              " ('🍭', 1.0): 1,\n",
              " ('nez', 1.0): 1,\n",
              " ('agnezmo', 1.0): 1,\n",
              " ('oley', 1.0): 1,\n",
              " ('\"', 1.0): 207,\n",
              " ('mama', 1.0): 1,\n",
              " ('only', 1.0): 46,\n",
              " ('why', 1.0): 25,\n",
              " ('stand', 1.0): 3,\n",
              " ('stronger', 1.0): 1,\n",
              " ('up', 1.0): 114,\n",
              " ('god', 1.0): 14,\n",
              " ('misty', 1.0): 1,\n",
              " ('baby', 1.0): 17,\n",
              " ('cute', 1.0): 21,\n",
              " ('woohoo', 1.0): 3,\n",
              " (\"can't\", 1.0): 31,\n",
              " ('wait', 1.0): 32,\n",
              " ('signed', 1.0): 3,\n",
              " ('yet', 1.0): 12,\n",
              " ('or', 1.0): 45,\n",
              " ('still', 1.0): 37,\n",
              " ('thinking', 1.0): 8,\n",
              " ('about', 1.0): 95,\n",
              " ('mka', 1.0): 5,\n",
              " ('liam', 1.0): 5,\n",
              " ('access', 1.0): 3,\n",
              " ('most', 1.0): 24,\n",
              " ('welcome', 1.0): 51,\n",
              " ('stats', 1.0): 51,\n",
              " ('day', 1.0): 157,\n",
              " ('arrived', 1.0): 55,\n",
              " ('1', 1.0): 60,\n",
              " ('follower', 1.0): 40,\n",
              " ('unfollowers', 1.0): 51,\n",
              " ('via', 1.0): 60,\n",
              " (\"shouldn't\", 1.0): 2,\n",
              " ('surprised', 1.0): 2,\n",
              " ('figure', 1.0): 3,\n",
              " ('happybirthdayemilybett', 1.0): 1,\n",
              " ('wishing', 1.0): 12,\n",
              " ('all', 1.0): 157,\n",
              " ('sweet', 1.0): 16,\n",
              " ('talented', 1.0): 4,\n",
              " ('2', 1.0): 41,\n",
              " ('plans', 1.0): 5,\n",
              " ('down', 1.0): 23,\n",
              " ('drain', 1.0): 1,\n",
              " ('gotta', 1.0): 4,\n",
              " ('timezones', 1.0): 1,\n",
              " ('parents', 1.0): 3,\n",
              " ('proud', 1.0): 11,\n",
              " ('least', 1.0): 14,\n",
              " ('maybe', 1.0): 17,\n",
              " ('sometimes', 1.0): 9,\n",
              " ('because', 1.0): 28,\n",
              " ('grades', 1.0): 2,\n",
              " ('al', 1.0): 3,\n",
              " ('grande', 1.0): 3,\n",
              " ('manila_bro', 1.0): 1,\n",
              " ('chosen', 1.0): 1,\n",
              " ('let', 1.0): 48,\n",
              " (\"you're\", 1.0): 74,\n",
              " ('around', 1.0): 14,\n",
              " ('..', 1.0): 100,\n",
              " ('side', 1.0): 12,\n",
              " ('world', 1.0): 23,\n",
              " ('eh', 1.0): 2,\n",
              " ('too', 1.0): 107,\n",
              " ('take', 1.0): 25,\n",
              " ('care', 1.0): 9,\n",
              " ('finally', 1.0): 13,\n",
              " ('fucking', 1.0): 9,\n",
              " ('weekend', 1.0): 61,\n",
              " ('real', 1.0): 18,\n",
              " ('x45', 1.0): 1,\n",
              " ('joined', 1.0): 6,\n",
              " ('hushedcallwithfraydoe', 1.0): 1,\n",
              " ('gift', 1.0): 4,\n",
              " ('from', 1.0): 83,\n",
              " ('yeahhh', 1.0): 1,\n",
              " ('make', 1.0): 45,\n",
              " ('hushedpinwithsammy', 1.0): 2,\n",
              " ('event', 1.0): 6,\n",
              " ('might', 1.0): 21,\n",
              " ('luv', 1.0): 4,\n",
              " ('really', 1.0): 66,\n",
              " ('appreciate', 1.0): 17,\n",
              " ('share', 1.0): 19,\n",
              " ('wow', 1.0): 14,\n",
              " ('that', 1.0): 220,\n",
              " ('tom', 1.0): 5,\n",
              " ('gym', 1.0): 3,\n",
              " ('monday', 1.0): 7,\n",
              " ('likes', 1.0): 3,\n",
              " ('invite', 1.0): 14,\n",
              " ('join', 1.0): 12,\n",
              " ('scope', 1.0): 5,\n",
              " ('influencer', 1.0): 5,\n",
              " ('those', 1.0): 21,\n",
              " ('friends', 1.0): 19,\n",
              " ('themselves', 1.0): 3,\n",
              " ('nudes', 1.0): 1,\n",
              " ('sleep', 1.0): 32,\n",
              " ('birthday', 1.0): 51,\n",
              " ('want', 1.0): 54,\n",
              " ('t-shirts', 1.0): 1,\n",
              " ('cool', 1.0): 28,\n",
              " ('haw', 1.0): 1,\n",
              " ('phela', 1.0): 1,\n",
              " ('mom', 1.0): 6,\n",
              " ('obviously', 1.0): 1,\n",
              " ('him', 1.0): 31,\n",
              " ('prince', 1.0): 1,\n",
              " ('charming', 1.0): 1,\n",
              " ('stage', 1.0): 2,\n",
              " ('luck', 1.0): 26,\n",
              " ('tylers', 1.0): 1,\n",
              " ('hipster', 1.0): 1,\n",
              " ('glasses', 1.0): 1,\n",
              " ('marty', 1.0): 2,\n",
              " ('glad', 1.0): 41,\n",
              " ('joining', 1.0): 3,\n",
              " ('again', 1.0): 43,\n",
              " ('done', 1.0): 40,\n",
              " ('its', 1.0): 53,\n",
              " ('afternoon', 1.0): 7,\n",
              " ('lets', 1.0): 8,\n",
              " ('read', 1.0): 18,\n",
              " ('kahfi', 1.0): 1,\n",
              " ('before', 1.0): 20,\n",
              " ('finish', 1.0): 2,\n",
              " ('ohmyg', 1.0): 1,\n",
              " ('yaya', 1.0): 3,\n",
              " ('dub', 1.0): 1,\n",
              " ('doing', 1.0): 24,\n",
              " ('stalk', 1.0): 1,\n",
              " ('ig', 1.0): 3,\n",
              " ('gondooo', 1.0): 1,\n",
              " ('moo', 1.0): 2,\n",
              " ('tologooo', 1.0): 1,\n",
              " ('become', 1.0): 5,\n",
              " ('details', 1.0): 6,\n",
              " ('zzz', 1.0): 1,\n",
              " ('xx', 1.0): 33,\n",
              " ('physiotherapy', 1.0): 1,\n",
              " ('hashtag', 1.0): 3,\n",
              " ('custom', 1.0): 1,\n",
              " ('💪', 1.0): 1,\n",
              " ('monica', 1.0): 1,\n",
              " ('miss', 1.0): 13,\n",
              " ('sounds', 1.0): 16,\n",
              " ('morning', 1.0): 67,\n",
              " (\"that's\", 1.0): 49,\n",
              " ('takes', 1.0): 3,\n",
              " ('x43', 1.0): 1,\n",
              " ('definitely', 1.0): 19,\n",
              " ('try', 1.0): 19,\n",
              " ('tonight', 1.0): 15,\n",
              " ('then', 1.0): 34,\n",
              " ('took', 1.0): 7,\n",
              " ('advice', 1.0): 6,\n",
              " ('treviso', 1.0): 1,\n",
              " ('concert', 1.0): 22,\n",
              " ('city', 1.0): 26,\n",
              " ('country', 1.0): 19,\n",
              " (\"i'll\", 1.0): 73,\n",
              " ('start', 1.0): 41,\n",
              " ('fine', 1.0): 7,\n",
              " ('gorgeous', 1.0): 9,\n",
              " ('friend', 1.0): 21,\n",
              " (';', 1.0): 9,\n",
              " ('xo', 1.0): 2,\n",
              " ('oven', 1.0): 2,\n",
              " ('roasted', 1.0): 1,\n",
              " ('garlic', 1.0): 1,\n",
              " ('olive', 1.0): 1,\n",
              " ('oil', 1.0): 4,\n",
              " ('dried', 1.0): 2,\n",
              " ('tomatoes', 1.0): 1,\n",
              " ('some', 1.0): 81,\n",
              " ('basil', 1.0): 1,\n",
              " ('century', 1.0): 1,\n",
              " ('tuna', 1.0): 1,\n",
              " ('right', 1.0): 37,\n",
              " ('back', 1.0): 73,\n",
              " ('atchya', 1.0): 1,\n",
              " (\"doesn't\", 1.0): 15,\n",
              " ('even', 1.0): 24,\n",
              " ('almost', 1.0): 8,\n",
              " ('chance', 1.0): 3,\n",
              " ('cheers', 1.0): 17,\n",
              " ('po', 1.0): 3,\n",
              " ('ice', 1.0): 6,\n",
              " ('cream', 1.0): 6,\n",
              " ('agree', 1.0): 11,\n",
              " ('100', 1.0): 6,\n",
              " ('%', 1.0): 5,\n",
              " ('hehehehe', 1.0): 2,\n",
              " ('thats', 1.0): 10,\n",
              " ('point', 1.0): 7,\n",
              " ('stay', 1.0): 17,\n",
              " ('home', 1.0): 20,\n",
              " ('soon', 1.0): 38,\n",
              " ('promise', 1.0): 4,\n",
              " ('web', 1.0): 4,\n",
              " ('whatsapp', 1.0): 2,\n",
              " ('volta', 1.0): 1,\n",
              " ('funcionar', 1.0): 1,\n",
              " ('com', 1.0): 2,\n",
              " ('iphone', 1.0): 7,\n",
              " ('jailbroken', 1.0): 1,\n",
              " ('plan', 1.0): 10,\n",
              " ('watching', 1.0): 11,\n",
              " ('later', 1.0): 11,\n",
              " ('34', 1.0): 3,\n",
              " ('mins', 1.0): 6,\n",
              " ('leia', 1.0): 1,\n",
              " ('appears', 1.0): 2,\n",
              " ('hologram', 1.0): 1,\n",
              " ('r2d2', 1.0): 1,\n",
              " ('w', 1.0): 16,\n",
              " ('message', 1.0): 7,\n",
              " ('obi', 1.0): 1,\n",
              " ('wan', 1.0): 1,\n",
              " ('he', 1.0): 46,\n",
              " ('sits', 1.0): 2,\n",
              " ('luke', 1.0): 4,\n",
              " ('inter', 1.0): 1,\n",
              " ('3', 1.0): 24,\n",
              " ('ucl', 1.0): 1,\n",
              " ('arsenal', 1.0): 2,\n",
              " ('small', 1.0): 1,\n",
              " ('team', 1.0): 24,\n",
              " ('passing', 1.0): 1,\n",
              " ('🚂', 1.0): 1,\n",
              " ('@', 1.0): 14,\n",
              " ('dewsbury', 1.0): 2,\n",
              " ('railway', 1.0): 1,\n",
              " ('station', 1.0): 4,\n",
              " ('dew', 1.0): 1,\n",
              " ('west', 1.0): 1,\n",
              " ('yorkshire', 1.0): 2,\n",
              " ('430', 1.0): 1,\n",
              " ('smh', 1.0): 2,\n",
              " (\"it's\", 1.0): 115,\n",
              " ('9:25', 1.0): 1,\n",
              " ('live', 1.0): 15,\n",
              " ('strange', 1.0): 3,\n",
              " ('imagine', 1.0): 4,\n",
              " ('what', 1.0): 87,\n",
              " ('megan', 1.0): 1,\n",
              " ('masaantodaymasaantodaya', 1.0): 1,\n",
              " ('4', 1.0): 23,\n",
              " ('shweta', 1.0): 1,\n",
              " ('tripathi', 1.0): 1,\n",
              " ('masaantodaymasaantoday', 1.0): 1,\n",
              " ('5', 1.0): 15,\n",
              " ('over', 1.0): 25,\n",
              " ('20', 1.0): 5,\n",
              " ('kurtas', 1.0): 1,\n",
              " ('half', 1.0): 6,\n",
              " ('number', 1.0): 11,\n",
              " ('wsalelove', 1.0): 13,\n",
              " ('ah', 1.0): 12,\n",
              " ('larry', 1.0): 3,\n",
              " ('anyway', 1.0): 14,\n",
              " ('kinda', 1.0): 12,\n",
              " ('goood', 1.0): 1,\n",
              " ('life', 1.0): 36,\n",
              " ('enn', 1.0): 1,\n",
              " ('surely', 1.0): 2,\n",
              " ('could', 1.0): 25,\n",
              " ('warmup', 1.0): 1,\n",
              " ('coming', 1.0): 16,\n",
              " ('15th', 1.0): 2,\n",
              " ('bath', 1.0): 6,\n",
              " ('dum', 1.0): 2,\n",
              " ('andar', 1.0): 1,\n",
              " ('ram', 1.0): 1,\n",
              " ('sampath', 1.0): 1,\n",
              " ('sona', 1.0): 1,\n",
              " ('mohapatra', 1.0): 1,\n",
              " ('samantha', 1.0): 1,\n",
              " ('edwards', 1.0): 1,\n",
              " ('mein', 1.0): 1,\n",
              " ('tulane', 1.0): 1,\n",
              " ('razi', 1.0): 2,\n",
              " ('wah', 1.0): 2,\n",
              " ('josh', 1.0): 1,\n",
              " ('always', 1.0): 48,\n",
              " ('smile', 1.0): 30,\n",
              " ('picture', 1.0): 5,\n",
              " ('16.20', 1.0): 1,\n",
              " ('timing', 1.0): 4,\n",
              " ('giveitup', 1.0): 1,\n",
              " ('given', 1.0): 3,\n",
              " ('gas', 1.0): 1,\n",
              " ('subsidy', 1.0): 1,\n",
              " ('initiative', 1.0): 1,\n",
              " ('proposed', 1.0): 1,\n",
              " ('feeling', 1.0): 9,\n",
              " ('delighted', 1.0): 3,\n",
              " ('having', 1.0): 23,\n",
              " ('missed', 1.0): 2,\n",
              " ('yesterday', 1.0): 4,\n",
              " ('x42', 1.0): 1,\n",
              " ('lmaoo', 1.0): 2,\n",
              " ('songs', 1.0): 5,\n",
              " ('ever', 1.0): 19,\n",
              " ('shall', 1.0): 5,\n",
              " ('own', 1.0): 3,\n",
              " ('little', 1.0): 29,\n",
              " ('throwback', 1.0): 3,\n",
              " ('outlying', 1.0): 1,\n",
              " ('islands', 1.0): 1,\n",
              " ('such', 1.0): 17,\n",
              " ('cheung', 1.0): 1,\n",
              " ('chau', 1.0): 1,\n",
              " ('mui', 1.0): 1,\n",
              " ('wo', 1.0): 1,\n",
              " ('totally', 1.0): 4,\n",
              " ('different', 1.0): 7,\n",
              " ('kfckitchentours', 1.0): 2,\n",
              " ('kitchen', 1.0): 3,\n",
              " ('clean', 1.0): 1,\n",
              " (\"i'm\", 1.0): 140,\n",
              " ('amazed', 1.0): 1,\n",
              " ('cusp', 1.0): 1,\n",
              " ('testing', 1.0): 2,\n",
              " ('waters', 1.0): 1,\n",
              " ('yours', 1.0): 9,\n",
              " ('rewarding', 1.0): 1,\n",
              " ('arummzz', 1.0): 2,\n",
              " (\"let's\", 1.0): 18,\n",
              " ('drive', 1.0): 4,\n",
              " ('traveling', 1.0): 4,\n",
              " ('traveler', 1.0): 3,\n",
              " ('yogyakarta', 1.0): 3,\n",
              " ('jeep', 1.0): 3,\n",
              " ('indonesia', 1.0): 3,\n",
              " ('instamood', 1.0): 3,\n",
              " ('wanna', 1.0): 23,\n",
              " ('skype', 1.0): 3,\n",
              " ('may', 1.0): 16,\n",
              " ('look', 1.0): 37,\n",
              " ('nice', 1.0): 70,\n",
              " ('friendly', 1.0): 1,\n",
              " ('them', 1.0): 48,\n",
              " ('pretend', 1.0): 2,\n",
              " ('~', 1.0): 19,\n",
              " ('where', 1.0): 20,\n",
              " ('film', 1.0): 4,\n",
              " ('congratulations', 1.0): 8,\n",
              " ('winner', 1.0): 3,\n",
              " ('cheesydelights', 1.0): 1,\n",
              " ('contest', 1.0): 5,\n",
              " ('address', 1.0): 8,\n",
              " ('guys', 1.0): 39,\n",
              " ('seeing', 1.0): 14,\n",
              " ('marketing', 1.0): 2,\n",
              " ('24/7', 1.0): 1,\n",
              " ('14', 1.0): 1,\n",
              " ('hours', 1.0): 15,\n",
              " ('leave', 1.0): 8,\n",
              " ('without', 1.0): 9,\n",
              " ('delays', 1.0): 1,\n",
              " ('actually', 1.0): 13,\n",
              " ('very', 1.0): 63,\n",
              " ('easy', 1.0): 7,\n",
              " ('guess', 1.0): 8,\n",
              " ('train', 1.0): 4,\n",
              " (\"'\", 1.0): 75,\n",
              " ('wd', 1.0): 1,\n",
              " ('hour', 1.0): 9,\n",
              " ('shifting', 1.0): 1,\n",
              " ('engine', 1.0): 1,\n",
              " ('etc', 1.0): 2,\n",
              " ('sunburn', 1.0): 1,\n",
              " ('peeling', 1.0): 1,\n",
              " ('blog', 1.0): 24,\n",
              " ('huge', 1.0): 9,\n",
              " ('warm', 1.0): 4,\n",
              " ('☆', 1.0): 3,\n",
              " ('complete', 1.0): 4,\n",
              " ('triangle', 1.0): 2,\n",
              " ('northern', 1.0): 1,\n",
              " ('ireland', 1.0): 2,\n",
              " ('sights', 1.0): 1,\n",
              " ('smthng', 1.0): 2,\n",
              " ('fr', 1.0): 3,\n",
              " ('hug', 1.0): 2,\n",
              " ('xoxo', 1.0): 3,\n",
              " ('uu', 1.0): 1,\n",
              " ('jaann', 1.0): 1,\n",
              " ('*', 1.0): 51,\n",
              " ('topnewfollowers', 1.0): 2,\n",
              " ('connect', 1.0): 6,\n",
              " ('wonderful', 1.0): 16,\n",
              " ('made', 1.0): 38,\n",
              " ('fluffy', 1.0): 1,\n",
              " ('inside', 1.0): 7,\n",
              " ('pirouette', 1.0): 1,\n",
              " ('moose', 1.0): 1,\n",
              " ('trip', 1.0): 11,\n",
              " ('philly', 1.0): 1,\n",
              " ('december', 1.0): 2,\n",
              " (\"i'd\", 1.0): 13,\n",
              " ('dude', 1.0): 5,\n",
              " ('x41', 1.0): 1,\n",
              " ('question', 1.0): 11,\n",
              " ('flawed', 1.0): 1,\n",
              " ('pain', 1.0): 7,\n",
              " ('negate', 1.0): 1,\n",
              " ('strength', 1.0): 2,\n",
              " ('went', 1.0): 10,\n",
              " ('solo', 1.0): 4,\n",
              " ('moves', 1.0): 1,\n",
              " (\"weren't\", 1.0): 3,\n",
              " ('fav', 1.0): 11,\n",
              " ('nirvana', 1.0): 1,\n",
              " ('song', 1.0): 11,\n",
              " ('smells', 1.0): 1,\n",
              " ('teen', 1.0): 2,\n",
              " ('spirit', 1.0): 1,\n",
              " ('rip', 1.0): 3,\n",
              " ('amy', 1.0): 3,\n",
              " ('winehouse', 1.0): 1,\n",
              " ('did', 1.0): 32,\n",
              " ('couple', 1.0): 4,\n",
              " ('tomhiddleston', 1.0): 1,\n",
              " ('elizabetholsen', 1.0): 1,\n",
              " ('yaytheylookgreat', 1.0): 1,\n",
              " ('goodnight', 1.0): 18,\n",
              " ('vid', 1.0): 6,\n",
              " ('wake', 1.0): 4,\n",
              " ('gonna', 1.0): 16,\n",
              " ('shoot', 1.0): 3,\n",
              " ('itty', 1.0): 2,\n",
              " ('bitty', 1.0): 2,\n",
              " ('teenie', 1.0): 2,\n",
              " ('bikini', 1.0): 2,\n",
              " ('much', 1.0): 73,\n",
              " ('4th', 1.0): 4,\n",
              " ('gets', 1.0): 5,\n",
              " ('together', 1.0): 6,\n",
              " ('ending', 1.0): 1,\n",
              " ('xfiles', 1.0): 1,\n",
              " ('content', 1.0): 3,\n",
              " ('rain', 1.0): 15,\n",
              " ('fabulous', 1.0): 4,\n",
              " ('fantastic', 1.0): 8,\n",
              " ('work', 1.0): 52,\n",
              " ('♡', 1.0): 12,\n",
              " ('jb', 1.0): 1,\n",
              " ('forever', 1.0): 5,\n",
              " ('belieber', 1.0): 2,\n",
              " ('hear', 1.0): 23,\n",
              " ('nighty', 1.0): 1,\n",
              " ('bugs', 1.0): 1,\n",
              " ('bite', 1.0): 1,\n",
              " ('bracelet', 1.0): 2,\n",
              " ('idea', 1.0): 18,\n",
              " ('foundry', 1.0): 1,\n",
              " ('game', 1.0): 17,\n",
              " ('sense', 1.0): 6,\n",
              " (\"didn't\", 1.0): 16,\n",
              " ('pic', 1.0): 14,\n",
              " ('effing', 1.0): 1,\n",
              " ('phone', 1.0): 14,\n",
              " ('woot', 1.0): 2,\n",
              " ('derek', 1.0): 1,\n",
              " ('using', 1.0): 7,\n",
              " ('parkshare', 1.0): 1,\n",
              " ('gloucestershire', 1.0): 1,\n",
              " ('aaaahhh', 1.0): 1,\n",
              " ('man', 1.0): 15,\n",
              " ('traffic', 1.0): 2,\n",
              " ('stress', 1.0): 4,\n",
              " ('reliever', 1.0): 1,\n",
              " (\"how're\", 1.0): 1,\n",
              " ('arbeloa', 1.0): 1,\n",
              " ('turning', 1.0): 3,\n",
              " ('17', 1.0): 2,\n",
              " ('omg', 1.0): 13,\n",
              " ('difference', 1.0): 1,\n",
              " ('say', 1.0): 30,\n",
              " ('europe', 1.0): 1,\n",
              " ('rise', 1.0): 1,\n",
              " ('find', 1.0): 16,\n",
              " ('hard', 1.0): 9,\n",
              " ('believe', 1.0): 7,\n",
              " ('uncountable', 1.0): 1,\n",
              " ('coz', 1.0): 2,\n",
              " ('unlimited', 1.0): 1,\n",
              " ('course', 1.0): 11,\n",
              " ('teampositive', 1.0): 1,\n",
              " ('aldub', 1.0): 2,\n",
              " ('☕', 1.0): 3,\n",
              " ('rita', 1.0): 2,\n",
              " ('further', 1.0): 2,\n",
              " ('info', 1.0): 10,\n",
              " (\"we'd\", 1.0): 4,\n",
              " ('way', 1.0): 33,\n",
              " ('boy', 1.0): 10,\n",
              " ('gifts', 1.0): 1,\n",
              " ('x40', 1.0): 1,\n",
              " ('true', 1.0): 18,\n",
              " ('sethi', 1.0): 2,\n",
              " ('high', 1.0): 6,\n",
              " ('exe', 1.0): 1,\n",
              " ('skeem', 1.0): 1,\n",
              " ('saam', 1.0): 1,\n",
              " ('people', 1.0): 41,\n",
              " ('polite', 1.0): 2,\n",
              " ('izzat', 1.0): 1,\n",
              " ('wese', 1.0): 1,\n",
              " ('does', 1.0): 22,\n",
              " ('trust', 1.0): 5,\n",
              " ('khawateen', 1.0): 1,\n",
              " ('k', 1.0): 8,\n",
              " ('sath', 1.0): 2,\n",
              " ('mana', 1.0): 1,\n",
              " ('kar', 1.0): 1,\n",
              " ('deya', 1.0): 1,\n",
              " ('evening', 1.0): 2,\n",
              " ('sorted', 1.0): 4,\n",
              " ('smart', 1.0): 5,\n",
              " ('hair', 1.0): 6,\n",
              " ('tbh', 1.0): 5,\n",
              " ('jacob', 1.0): 2,\n",
              " ('m', 1.0): 10,\n",
              " ('g', 1.0): 6,\n",
              " ('upgrade', 1.0): 1,\n",
              " ('tee', 1.0): 2,\n",
              " ('family', 1.0): 13,\n",
              " ('reading', 1.0): 9,\n",
              " ('talking', 1.0): 13,\n",
              " ('person', 1.0): 10,\n",
              " ('two', 1.0): 15,\n",
              " ('conversations', 1.0): 2,\n",
              " ('should', 1.0): 27,\n",
              " ('online', 1.0): 4,\n",
              " ('mclaren', 1.0): 1,\n",
              " ('fridayfeeling', 1.0): 5,\n",
              " ('tgif', 1.0): 8,\n",
              " ('square', 1.0): 1,\n",
              " ('enix', 1.0): 1,\n",
              " ('bissmillah', 1.0): 1,\n",
              " ('ya', 1.0): 19,\n",
              " ('allah', 1.0): 3,\n",
              " (\"we're\", 1.0): 25,\n",
              " ('training', 1.0): 3,\n",
              " ('socent', 1.0): 1,\n",
              " ('startups', 1.0): 1,\n",
              " ('/', 1.0): 52,\n",
              " ('drop', 1.0): 8,\n",
              " ('youre', 1.0): 3,\n",
              " ('arnd', 1.0): 1,\n",
              " ('town', 1.0): 2,\n",
              " ('basically', 1.0): 4,\n",
              " ('piss', 1.0): 1,\n",
              " ('cup', 1.0): 4,\n",
              " ('test', 1.0): 4,\n",
              " ('also', 1.0): 28,\n",
              " ('terrible', 1.0): 2,\n",
              " ('complicated', 1.0): 1,\n",
              " ('discussions', 1.0): 1,\n",
              " ('snapchat', 1.0): 31,\n",
              " ('lynettelowe', 1.0): 1,\n",
              " ('kikmenow', 1.0): 2,\n",
              " ('snapme', 1.0): 1,\n",
              " ('hot', 1.0): 20,\n",
              " ('amazon', 1.0): 1,\n",
              " ('kikmeguys', 1.0): 2,\n",
              " ('shift', 1.0): 3,\n",
              " ('definately', 1.0): 1,\n",
              " ('growing', 1.0): 4,\n",
              " ('sport', 1.0): 2,\n",
              " ('rt', 1.0): 3,\n",
              " ('rakyat', 1.0): 1,\n",
              " ('writing', 1.0): 5,\n",
              " ('since', 1.0): 11,\n",
              " ('mentioned', 1.0): 3,\n",
              " ('fly', 1.0): 4,\n",
              " ('fishing', 1.0): 1,\n",
              " ('other', 1.0): 13,\n",
              " ('getting', 1.0): 24,\n",
              " ('follows', 1.0): 4,\n",
              " ('promoted', 1.0): 1,\n",
              " ('posts', 1.0): 1,\n",
              " ('cyber', 1.0): 1,\n",
              " ('stalked', 1.0): 1,\n",
              " ('ourdaughtersourpride', 1.0): 3,\n",
              " ('mypapamypride', 1.0): 2,\n",
              " ('papa', 1.0): 1,\n",
              " ('coach', 1.0): 2,\n",
              " ('positive', 1.0): 3,\n",
              " ('kha', 1.0): 1,\n",
              " ('mention', 1.0): 12,\n",
              " ('atleast', 1.0): 2,\n",
              " ('x39', 1.0): 1,\n",
              " ('mango', 1.0): 1,\n",
              " (\"lassi's\", 1.0): 1,\n",
              " (\"monty's\", 1.0): 1,\n",
              " ('marvellous', 1.0): 1,\n",
              " ('though', 1.0): 16,\n",
              " ('suspect', 1.0): 2,\n",
              " ('meant', 1.0): 2,\n",
              " ('24', 1.0): 3,\n",
              " ('hrs', 1.0): 1,\n",
              " ('touch', 1.0): 7,\n",
              " ('kepler', 1.0): 3,\n",
              " ('452b', 1.0): 4,\n",
              " ('chalna', 1.0): 1,\n",
              " ('hai', 1.0): 6,\n",
              " ('thankyou', 1.0): 12,\n",
              " ('hazel', 1.0): 1,\n",
              " ('food', 1.0): 6,\n",
              " ('market', 1.0): 3,\n",
              " ('brooklyn', 1.0): 1,\n",
              " ('pta', 1.0): 2,\n",
              " ('awake', 1.0): 7,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract your features vectors to use as input for the model.**"
      ],
      "metadata": {
        "id": "HTwGgvyama8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# collect the features 'x' and stack them into a  matrix X\n",
        "X = np.zeros((len(train_x), 3))\n",
        "for i in range(len(train_x)):\n",
        "  X[i, :] = extract_features(train_x[i], freqs)"
      ],
      "metadata": {
        "id": "VLkk5jGMmUPa"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtnHah-1m-Fe",
        "outputId": "56f3ffd1-40cd-48b2-f3c8-01c2c924f33b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0000e+00, 4.7200e+03, 1.6120e+03],\n",
              "       [1.0000e+00, 9.7950e+03, 4.4950e+03],\n",
              "       [1.0000e+00, 1.0336e+04, 5.0490e+03],\n",
              "       ...,\n",
              "       [1.0000e+00, 2.1240e+03, 4.4770e+03],\n",
              "       [1.0000e+00, 1.9710e+03, 6.5940e+03],\n",
              "       [1.0000e+00, 5.7830e+03, 1.0346e+04]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "X_df = pd.DataFrame(X)"
      ],
      "metadata": {
        "id": "LvXKWg9knAys"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dx87h6fEnMyo",
        "outputId": "3d2c432d-7d0e-4497-bb91-ae2d261ed2ef"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0        1        2\n",
              "0     1.0   4720.0   1612.0\n",
              "1     1.0   9795.0   4495.0\n",
              "2     1.0  10336.0   5049.0\n",
              "3     1.0   2862.0      4.0\n",
              "4     1.0   9593.0   4481.0\n",
              "...   ...      ...      ...\n",
              "7995  1.0    469.0   4309.0\n",
              "7996  1.0   3810.0   5180.0\n",
              "7997  1.0   2124.0   4477.0\n",
              "7998  1.0   1971.0   6594.0\n",
              "7999  1.0   5783.0  10346.0\n",
              "\n",
              "[8000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8acc38b1-7bd9-467e-aa68-3b2d458ea0c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4720.0</td>\n",
              "      <td>1612.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9795.0</td>\n",
              "      <td>4495.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>10336.0</td>\n",
              "      <td>5049.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2862.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9593.0</td>\n",
              "      <td>4481.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>1.0</td>\n",
              "      <td>469.0</td>\n",
              "      <td>4309.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3810.0</td>\n",
              "      <td>5180.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2124.0</td>\n",
              "      <td>4477.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1971.0</td>\n",
              "      <td>6594.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>1.0</td>\n",
              "      <td>5783.0</td>\n",
              "      <td>10346.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8acc38b1-7bd9-467e-aa68-3b2d458ea0c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8acc38b1-7bd9-467e-aa68-3b2d458ea0c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8acc38b1-7bd9-467e-aa68-3b2d458ea0c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_df.to_csv('features_extracted.csv')"
      ],
      "metadata": {
        "id": "K9jx_tmJnN6E"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prepare your real output Y\n"
      ],
      "metadata": {
        "id": "h-HQmRByndvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training labels corresponding to X\n",
        "Y = train_y"
      ],
      "metadata": {
        "id": "D_dg4Rl0nZv4"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4wset7Bnnuw",
        "outputId": "f789ad84-cd2e-424e-b3a8-85bc8586ab44"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       ...,\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prepare LR functions: Sigmoid"
      ],
      "metadata": {
        "id": "-2BlskcsYTG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))"
      ],
      "metadata": {
        "id": "tMyTtS3onoYo"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare LR functions: Gradient descent"
      ],
      "metadata": {
        "id": "QE9ixBRLYggs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gredientDescent(x, y, theta, alpha, num_iters):\n",
        "  '''\n",
        "  Input:\n",
        "  x : matrix of features which is (m, n+1)\n",
        "  y : corresponding labels of the input matrix x , dimensions (m, 1)\n",
        "  theta : weight vector of dimension (n+1, 1)\n",
        "  num_iters : number of iterations you want to train your model for \n",
        "\n",
        "  Output:\n",
        "  J : the final coast\n",
        "  theta : your final weight vector \n",
        "  ''' \n",
        "  #get 'm' , the number of rows in matrix x\n",
        "  m = x.shape[0]\n",
        "  for i in range(0, num_iters):\n",
        "    #get z, the dot product of x and theta\n",
        "    z = np.dot(x, theta)\n",
        "    #get the sigmoid of z\n",
        "    h = sigmoid(z)\n",
        "    #calculate the cost function \n",
        "    J = (-1/m )* (np.dot(y.transpose(), np.log(h)) + np.dot((1-y).transpose(), np.log(1-h)))\n",
        "\n",
        "    #update the weights theta\n",
        "    theta = theta - (alpha / m) * np.dot(x.transpose(), (h-y))\n",
        "  J = float(J)\n",
        "  return J, theta\n",
        "\n"
      ],
      "metadata": {
        "id": "DV8sJi9_YcQ5"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Applying gradient descent\n"
      ],
      "metadata": {
        "id": "S9qdqncQbNhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "J, theta = gredientDescent(X,Y, np.zeros((3,1)), 1e-9, 1500)"
      ],
      "metadata": {
        "id": "j2P_4f_1bHGI"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The cost after training is {J:.8f}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMVnGwYtbbUc",
        "outputId": "801a1a83-f579-4645-cb11-81abf919bb68"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cost after training is 0.21937448.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZycXiZAYbt6l",
        "outputId": "6199d44c-aeb5-46c0-9c7d-1e14932ed24b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The resulting vector of weights is [4e-08, 0.00055706, -0.00052673]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#function for predicting tweets\n"
      ],
      "metadata": {
        "id": "pxu7vxMgcUbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tweets(tweet, freqs, theta):\n",
        "  '''\n",
        "  Input:\n",
        "  tweet : a string\n",
        "  freqs : a dictionary corresponding to the frequencies of each tuple (word, label)\n",
        "  theta : (3, 1) vector of weights \n",
        "  Output:\n",
        "  y_pred: the probability of a tweet being positive or negative\n",
        "  '''\n",
        "  #extract the features of the tweet and store it into x\n",
        "  x = extract_features(tweet, freqs)\n",
        "\n",
        "  # make the prediction using x and theta \n",
        "  y_pred = sigmoid(np.dot(x, theta))\n",
        "\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "Eo8oFJalcCfh"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "QaZQ6qpZdpD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_to_predict = ['I am happy', 'I am sad', 'my name is Mohamed Ali']"
      ],
      "metadata": {
        "id": "o7v7paJhdlW0"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tweet in tweets_to_predict:\n",
        "  print('%s -> %f' % (tweet, predict_tweets(tweet, freqs, theta)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxsVdueud4XT",
        "outputId": "3ced0c28-479d-4e74-9002-7d5e40fed0f7"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am happy -> 0.408673\n",
            "I am sad -> 0.379219\n",
            "my name is Mohamed Ali -> 0.481480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing the accuracy of the model"
      ],
      "metadata": {
        "id": "LQ91xUf2eSMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag.hmm import accuracy\n",
        "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
        "  '''\n",
        "  Input: \n",
        "      test_x: a list of tweets\n",
        "      test_y: (m, 1) vector with the corresponding labels for the list of tweets\n",
        "      freqs : a dictionary with the frequency of each pair or tuple\n",
        "      theta : weight vector of dimension (3, 1)\n",
        "  Output:\n",
        "      accuracy: # of tweets classified correctly / total # tweets\n",
        "  '''\n",
        "\n",
        "  y_hat = []\n",
        "  for tweet in test_x:\n",
        "    y_pred = predict_tweets(tweet, freqs, theta)\n",
        "\n",
        "    if y_pred > 0.5:\n",
        "      y_hat.append(1)\n",
        "    else:\n",
        "      y_hat.append(0)\n",
        "  accuracy = (y_hat == np.squeeze(test_y)).sum() // len(test_x)\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "R-R1JlbAeLMw"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_tweet = 'My name is Mohamed , I am a good Machine Learning Engineer'\n",
        "print(process_tweet(my_tweet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgR1Uq5FgDrr",
        "outputId": "9f12e2a6-8dac-4fa8-fc5f-1caca851b992"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['my', 'name', 'is', 'mohamed', ',', 'i', 'am', 'a', 'good', 'machine', 'learning', 'engineer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = predict_tweets(my_tweet, freqs, theta)"
      ],
      "metadata": {
        "id": "CfX0LvUqgWxI"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUj_V61mgfX9",
        "outputId": "03d512c8-43b4-4024-a3c0-3623c17a3399"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4491331]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if y_hat > 0.5:\n",
        "  print('Pos ')\n",
        "else:\n",
        "  print('Neg ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKWW5tDnghBY",
        "outputId": "3bb77b00-2f87-4ce6-bed5-ff03e210094f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neg \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HfTKpuTbgrsx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}